# Tips
## 1. basic
### 1.2 common mistakes

1. overfit single batch
2. set training as model.train() and set evaluate as model.eval()
3. pay attention to .zero_grad()
4. do not combine CrossEntropy and softmax 
5. set bias=Flase when use batchnorm
6. clipping gradients when use RNN, GRU, LSTM # nn.utils.clip_grad_norm(model.parameters, max_norm=1 )

### 1.3 Progress Bar

```python
from tqdm import tqdm
loop = tqdm(enumetate(data_loader), total=len(data_loader), leave=False) # leave=False, one bar
for batch_idx, (data, targets) in loop:
    ...
    loop.set_description(f"Epoch [{epoch}/{num_epochs}]")
    loop.set_postfix(loss=, acc=)
    
```



### 1.3 Reproducible result

```python
seed = 42
torch.manul_seed(seed)
np.random.seed(seed)
random.seed(seed)

# if using cuda
torch.cuda.manul_seed(seed)
torch.backends.cudnn.determinstic = True
torch.backends.cudnn.benchmark = False

```



### 1.4 Caculate Mean and Standard Deviation of Data

```python
# from data_loader
def get_mean_std(loader):
    channels_sum, channels_squared_sum, num_batches = 0, 0, 0
    for data, _ in loader:
        channels_sum += torch.mean(data, dim=[0, 2, 3])
        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])
        num_batches += 1
    mean = channels_sum / num_batches
    std = (channels_squared_sum / num_batches - mean**2)**0.5
    return mean, std
        
```



### 1.5 Weight Initialization

```python
class NN(nn.Module):
    def __init__():
        ...
        self.initialize_weights()
    def initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_uniform_(m.weight)

                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

            elif isinstance(m, nn.Linear):
                nn.init.kaiming_uniform_(m.weight)
                nn.init.constant_(m.bias, 0)
```



## 2. tensor board

```python
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter()

grid = torchvision.utils.make_grid(images)
writer.add_image('images', grid, 0)
writer.add_graph(model, images)
writer.close()
for epoch in range(num_epochs):
    writer.add_histogram("fc1", model.fc1.weight)
    writer.add_scalar("Training loss", loss, global_step=step)
    writer.add_embedding(
                            features,
                            metadata=class_labels,
                            label_img=data,
                            global_step=batch_idx,
                    )
    writer.add_hparams(
                    {"lr": learning_rate, "bsize": batch_size},
                    {
                        "accuracy": sum(accuracies) / len(accuracies),
                        "loss": sum(losses) / len(losses),
                    },
                )
```



