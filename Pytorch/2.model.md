# model

## 1.Train Model

```python
for epoch in range(num_epochs):
    data = data.to(device)
    socres = model(data)
    loss = criterion(scores, targets)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```



## 2. CNN

```python
class CNN(nn.Module):
    def __init(self, in_channels, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.fc = nn.Linear(16*7*7, num_classes)
    
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
		x = x.reshape(x.shape[0], -1)
        x = self.fc(x)
        return x
  
```



## 3. RNN

```python
class RNN(nn.Module):
    def __init(self, input_size, hidden_size, num_layers, num_classes):
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)
        
     def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.rnn(x, h0)
        out = out.reshape(out.shape[0], -1)
        out = self.fc(out)
        return out
```



## 4. GRU

```pyhton
class GRU(nn.Module):
    def __init(self, input_size, hidden_size, num_layers, num_classes):
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)
        
     def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.gru(x, h0)
        out = out.reshape(out.shape[0], -1)
        out = self.fc(out)
        return out
```



## 5. LSTM

```python
class LSTM(nn.Module):
    def __init(self, input_size, hidden_size, num_layers, num_classes):
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)
        
     def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.lstm(x, (h0, c0))
        out = out.reshape(out.shape[0], -1)
        out = self.fc(out)
        return out
```



## 6. Save and Load model

```python
def save_checkpoint(state, filename):
    print("=> Saving checkpoint")
    torch.save(state, filename) # .pth.tar
    
checkpoint = {'state_dict': model.state_dict(), 'optimizer':optimizer.state_dict()}
save_checkpoint(checkpoint)
    
def load_checkpoint(checkpoint):
    print("=> Load checkpoint")
    model.load_state_dict(checkpoint['state_dict'])
    optimizer.load_state_dict(checkpoint['state_dict'])
    
checkpoint = torch.load(filename)
load_checkpoint(checkpoint)
```



## 7. Pretrain and  Finetune

```python
class Identity(nn.Module):
    def __init__(self):
        super(Identity, self).__init__()

    def forward(self, x):
        return x
    
model = torchvision.models.vgg16(pretrained=True)
# must need
for param in model.parameters():
    param.requires_grad = False
# print(model) to see the structure of the network

model.avgpoll = Identity()
model.classifier = nn.Sequential(
    nn.Linear(512, 100), nn.ReLU(), nn.Linear(100, num_classes)
)
model.to(device) # or model.classfier[i]
```

